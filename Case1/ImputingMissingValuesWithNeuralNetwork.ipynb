{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leevi\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2      3      4    5    6      7    8    9    10   11   12  13\n",
       "0  63.0  1.0  1.0  145.0  233.0  1.0  2.0  150.0  0.0  2.3  3.0  0.0  6.0   0\n",
       "1  67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.5  2.0  3.0  3.0   2\n",
       "2  67.0  1.0  4.0  120.0  229.0  0.0  2.0  129.0  1.0  2.6  2.0  2.0  7.0   1\n",
       "3  37.0  1.0  3.0  130.0  250.0  0.0  0.0  187.0  0.0  3.5  3.0  0.0  3.0   0\n",
       "4  41.0  0.0  2.0  130.0  204.0  0.0  2.0  172.0  0.0  1.4  1.0  0.0  3.0   0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = r'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "df = pd.read_csv(filename,\n",
    "                index_col = None,\n",
    "                header = None,\n",
    "                na_values = '?')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neural networks to fill missing data values  \n",
    "  \n",
    "  ## Creating dataframes of Nan values and non Nan values\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2      3      4    5    6      7    8    9    10   11   12 13\n",
      "87   53.0  0.0  3.0  128.0  216.0  0.0  2.0  115.0  0.0  0.0  1.0    0  nan  0\n",
      "166  52.0  1.0  3.0  138.0  223.0  0.0  0.0  169.0  0.0  0.0  1.0  nan    3  0\n",
      "192  43.0  1.0  4.0  132.0  247.0  1.0  2.0  143.0  1.0  0.1  2.0  nan    7  1\n",
      "266  52.0  1.0  4.0  128.0  204.0  1.0  0.0  156.0  1.0  1.0  2.0    0  nan  2\n",
      "287  58.0  1.0  2.0  125.0  220.0  0.0  0.0  144.0  0.0  0.4  2.0  nan    7  0\n",
      "302  38.0  1.0  3.0  138.0  175.0  0.0  0.0  173.0  0.0  0.0  1.0  nan    3  0\n",
      "    0    1    2    3    4    5    6    7    8    9    10 11 12   13\n",
      "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1  1  NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2      3      4    5    6      7    8    9    10   11   12  13\n",
       "0  63.0  1.0  1.0  145.0  233.0  1.0  2.0  150.0  0.0  2.3  3.0  0.0  6.0   0\n",
       "1  67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.5  2.0  3.0  3.0   2\n",
       "2  67.0  1.0  4.0  120.0  229.0  0.0  2.0  129.0  1.0  2.6  2.0  2.0  7.0   1\n",
       "3  37.0  1.0  3.0  130.0  250.0  0.0  0.0  187.0  0.0  3.5  3.0  0.0  3.0   0\n",
       "4  41.0  0.0  2.0  130.0  204.0  0.0  2.0  172.0  0.0  1.4  1.0  0.0  3.0   0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#marking all the Nan values with String 'nan'\n",
    "df_nan = df.fillna('nan')\n",
    "\n",
    "#creating empty dataframe\n",
    "column_names = ([0,1,2,3,4,5,6,7,8,9,10,11,12,13])\n",
    "nan_data_columns = pd.DataFrame(columns = column_names)\n",
    "nan_data = pd.DataFrame(columns = column_names)\n",
    "\n",
    "i = 0\n",
    "#going through all the data rows\n",
    "while i < df.shape[0]:\n",
    "    contains_nan = 0\n",
    "    a = 0\n",
    "    \n",
    "    #going through all the columns in a row\n",
    "    for x in df_nan.loc[i,]:\n",
    "        \n",
    "        #if contains nan adding 1 to nan_data_columns so we know what columns have Nan values\n",
    "        if x == 'nan':\n",
    "            nan_data_columns.loc[1,a] = 1\n",
    "            contains_nan = 1\n",
    "        a = a + 1\n",
    "        \n",
    "    #if the row had Nan values adding it to nan_data dataframe    \n",
    "    if contains_nan == 1:\n",
    "        nan_data = nan_data.append(df_nan.loc[i, ])\n",
    "    i = i + 1\n",
    "\n",
    "print(nan_data)   \n",
    "print(nan_data_columns)\n",
    "\n",
    "#dropping Nan values so now df has all rows but the ones with Nan values\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Neural network for each column that has Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 52)                728       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 53        \n",
      "=================================================================\n",
      "Total params: 963\n",
      "Trainable params: 963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 297 samples\n",
      "Epoch 1/50\n",
      "297/297 [==============================] - 1s 2ms/sample - loss: 309.6536 - mae: 11.2659\n",
      "Epoch 2/50\n",
      "297/297 [==============================] - 0s 283us/sample - loss: 4.7866 - mae: 1.7066\n",
      "Epoch 3/50\n",
      "297/297 [==============================] - 0s 295us/sample - loss: 4.4071 - mae: 1.6918\n",
      "Epoch 4/50\n",
      "297/297 [==============================] - 0s 298us/sample - loss: 3.4769 - mae: 1.4951\n",
      "Epoch 5/50\n",
      "297/297 [==============================] - 0s 288us/sample - loss: 3.1604 - mae: 1.4152\n",
      "Epoch 6/50\n",
      "297/297 [==============================] - 0s 295us/sample - loss: 3.0103 - mae: 1.4224\n",
      "Epoch 7/50\n",
      "297/297 [==============================] - 0s 340us/sample - loss: 3.0121 - mae: 1.4029\n",
      "Epoch 8/50\n",
      "297/297 [==============================] - 0s 315us/sample - loss: 2.6777 - mae: 1.3779\n",
      "Epoch 9/50\n",
      "297/297 [==============================] - 0s 320us/sample - loss: 2.7390 - mae: 1.4069\n",
      "Epoch 10/50\n",
      "297/297 [==============================] - 0s 270us/sample - loss: 2.1755 - mae: 1.1804\n",
      "Epoch 11/50\n",
      "297/297 [==============================] - 0s 302us/sample - loss: 3.0125 - mae: 1.3303\n",
      "Epoch 12/50\n",
      "297/297 [==============================] - 0s 286us/sample - loss: 2.6947 - mae: 1.3293\n",
      "Epoch 13/50\n",
      "297/297 [==============================] - 0s 288us/sample - loss: 2.3521 - mae: 1.1824\n",
      "Epoch 14/50\n",
      "297/297 [==============================] - 0s 288us/sample - loss: 2.6345 - mae: 1.3092\n",
      "Epoch 15/50\n",
      "297/297 [==============================] - 0s 362us/sample - loss: 2.2968 - mae: 1.1839\n",
      "Epoch 16/50\n",
      "297/297 [==============================] - 0s 278us/sample - loss: 2.5968 - mae: 1.3428\n",
      "Epoch 17/50\n",
      "297/297 [==============================] - 0s 299us/sample - loss: 2.8367 - mae: 1.4450\n",
      "Epoch 18/50\n",
      "297/297 [==============================] - 0s 309us/sample - loss: 2.0028 - mae: 1.1128\n",
      "Epoch 19/50\n",
      "297/297 [==============================] - 0s 260us/sample - loss: 2.3581 - mae: 1.3333\n",
      "Epoch 20/50\n",
      "297/297 [==============================] - 0s 297us/sample - loss: 1.9807 - mae: 1.1012\n",
      "Epoch 21/50\n",
      "297/297 [==============================] - 0s 297us/sample - loss: 2.0181 - mae: 1.1505\n",
      "Epoch 22/50\n",
      "297/297 [==============================] - 0s 262us/sample - loss: 2.3017 - mae: 1.2293\n",
      "Epoch 23/50\n",
      "297/297 [==============================] - 0s 325us/sample - loss: 2.0126 - mae: 1.1749\n",
      "Epoch 24/50\n",
      "297/297 [==============================] - 0s 244us/sample - loss: 2.2875 - mae: 1.3150\n",
      "Epoch 25/50\n",
      "297/297 [==============================] - 0s 282us/sample - loss: 1.5874 - mae: 0.9171\n",
      "Epoch 26/50\n",
      "297/297 [==============================] - 0s 304us/sample - loss: 2.2499 - mae: 1.2637\n",
      "Epoch 27/50\n",
      "297/297 [==============================] - 0s 302us/sample - loss: 2.2153 - mae: 1.2514\n",
      "Epoch 28/50\n",
      "297/297 [==============================] - 0s 336us/sample - loss: 1.5664 - mae: 1.0252\n",
      "Epoch 29/50\n",
      "297/297 [==============================] - 0s 346us/sample - loss: 1.8614 - mae: 1.0721\n",
      "Epoch 30/50\n",
      "297/297 [==============================] - 0s 319us/sample - loss: 1.4201 - mae: 0.9783\n",
      "Epoch 31/50\n",
      "297/297 [==============================] - 0s 280us/sample - loss: 2.1734 - mae: 1.1191\n",
      "Epoch 32/50\n",
      "297/297 [==============================] - 0s 331us/sample - loss: 1.7905 - mae: 1.0172\n",
      "Epoch 33/50\n",
      "297/297 [==============================] - 0s 307us/sample - loss: 1.6450 - mae: 1.0302\n",
      "Epoch 34/50\n",
      "297/297 [==============================] - 0s 353us/sample - loss: 1.6796 - mae: 1.1336\n",
      "Epoch 35/50\n",
      "297/297 [==============================] - 0s 285us/sample - loss: 1.4723 - mae: 0.9834\n",
      "Epoch 36/50\n",
      "297/297 [==============================] - ETA: 0s - loss: 2.1124 - mae: 1.159 - 0s 273us/sample - loss: 1.9274 - mae: 1.1000\n",
      "Epoch 37/50\n",
      "297/297 [==============================] - 0s 243us/sample - loss: 1.6947 - mae: 0.9108\n",
      "Epoch 38/50\n",
      "297/297 [==============================] - 0s 335us/sample - loss: 1.5902 - mae: 1.0658\n",
      "Epoch 39/50\n",
      "297/297 [==============================] - 0s 314us/sample - loss: 1.4781 - mae: 1.0335\n",
      "Epoch 40/50\n",
      "297/297 [==============================] - 0s 266us/sample - loss: 1.5134 - mae: 0.9018\n",
      "Epoch 41/50\n",
      "297/297 [==============================] - 0s 327us/sample - loss: 1.5878 - mae: 1.0029\n",
      "Epoch 42/50\n",
      "297/297 [==============================] - 0s 311us/sample - loss: 1.3328 - mae: 0.9776\n",
      "Epoch 43/50\n",
      "297/297 [==============================] - 0s 322us/sample - loss: 1.3437 - mae: 0.9488\n",
      "Epoch 44/50\n",
      "297/297 [==============================] - 0s 334us/sample - loss: 1.4118 - mae: 1.0322\n",
      "Epoch 45/50\n",
      "297/297 [==============================] - 0s 306us/sample - loss: 1.3988 - mae: 0.9558\n",
      "Epoch 46/50\n",
      "297/297 [==============================] - 0s 303us/sample - loss: 1.3403 - mae: 0.9302\n",
      "Epoch 47/50\n",
      "297/297 [==============================] - 0s 309us/sample - loss: 1.2649 - mae: 0.9618\n",
      "Epoch 48/50\n",
      "297/297 [==============================] - 0s 266us/sample - loss: 1.1620 - mae: 0.8740\n",
      "Epoch 49/50\n",
      "297/297 [==============================] - 0s 326us/sample - loss: 1.5239 - mae: 0.9796\n",
      "Epoch 50/50\n",
      "297/297 [==============================] - 0s 229us/sample - loss: 1.1892 - mae: 0.8331\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 52)                728       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 53        \n",
      "=================================================================\n",
      "Total params: 963\n",
      "Trainable params: 963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 297 samples\n",
      "Epoch 1/50\n",
      "297/297 [==============================] - 1s 2ms/sample - loss: 4.8550 - mae: 1.5974\n",
      "Epoch 2/50\n",
      "297/297 [==============================] - 0s 214us/sample - loss: 2.4644 - mae: 1.2086\n",
      "Epoch 3/50\n",
      "297/297 [==============================] - 0s 246us/sample - loss: 2.0373 - mae: 1.1986\n",
      "Epoch 4/50\n",
      "297/297 [==============================] - 0s 220us/sample - loss: 1.4956 - mae: 0.9791\n",
      "Epoch 5/50\n",
      "297/297 [==============================] - 0s 315us/sample - loss: 1.7626 - mae: 1.1976\n",
      "Epoch 6/50\n",
      "297/297 [==============================] - 0s 308us/sample - loss: 1.3983 - mae: 0.8578\n",
      "Epoch 7/50\n",
      "297/297 [==============================] - 0s 229us/sample - loss: 1.4878 - mae: 0.9586\n",
      "Epoch 8/50\n",
      "297/297 [==============================] - 0s 332us/sample - loss: 1.3312 - mae: 0.9589\n",
      "Epoch 9/50\n",
      "297/297 [==============================] - 0s 296us/sample - loss: 1.3607 - mae: 1.0036\n",
      "Epoch 10/50\n",
      "297/297 [==============================] - 0s 344us/sample - loss: 1.0921 - mae: 0.9568\n",
      "Epoch 11/50\n",
      "297/297 [==============================] - 0s 383us/sample - loss: 1.2228 - mae: 0.9719\n",
      "Epoch 12/50\n",
      "297/297 [==============================] - 0s 314us/sample - loss: 1.0587 - mae: 0.8995\n",
      "Epoch 13/50\n",
      "297/297 [==============================] - 0s 271us/sample - loss: 1.0609 - mae: 0.9333\n",
      "Epoch 14/50\n",
      "297/297 [==============================] - 0s 279us/sample - loss: 0.9542 - mae: 0.8104\n",
      "Epoch 15/50\n",
      "297/297 [==============================] - 0s 278us/sample - loss: 0.9923 - mae: 0.7339\n",
      "Epoch 16/50\n",
      "297/297 [==============================] - 0s 320us/sample - loss: 0.9480 - mae: 0.6977\n",
      "Epoch 17/50\n",
      "297/297 [==============================] - 0s 285us/sample - loss: 0.7830 - mae: 0.7395\n",
      "Epoch 18/50\n",
      "297/297 [==============================] - 0s 240us/sample - loss: 0.8140 - mae: 0.7284\n",
      "Epoch 19/50\n",
      "297/297 [==============================] - 0s 297us/sample - loss: 0.8165 - mae: 0.7548\n",
      "Epoch 20/50\n",
      "297/297 [==============================] - 0s 281us/sample - loss: 0.7733 - mae: 0.7528\n",
      "Epoch 21/50\n",
      "297/297 [==============================] - 0s 294us/sample - loss: 0.6497 - mae: 0.6638\n",
      "Epoch 22/50\n",
      "297/297 [==============================] - 0s 283us/sample - loss: 0.6559 - mae: 0.5758\n",
      "Epoch 23/50\n",
      "297/297 [==============================] - 0s 266us/sample - loss: 0.7457 - mae: 0.7255\n",
      "Epoch 24/50\n",
      "297/297 [==============================] - 0s 297us/sample - loss: 0.5050 - mae: 0.5442\n",
      "Epoch 25/50\n",
      "297/297 [==============================] - 0s 275us/sample - loss: 0.5590 - mae: 0.5800\n",
      "Epoch 26/50\n",
      "297/297 [==============================] - 0s 293us/sample - loss: 0.5185 - mae: 0.6281\n",
      "Epoch 27/50\n",
      "297/297 [==============================] - 0s 304us/sample - loss: 0.4487 - mae: 0.5484\n",
      "Epoch 28/50\n",
      "297/297 [==============================] - 0s 325us/sample - loss: 0.4926 - mae: 0.5985\n",
      "Epoch 29/50\n",
      "297/297 [==============================] - 0s 306us/sample - loss: 0.4008 - mae: 0.5202\n",
      "Epoch 30/50\n",
      "297/297 [==============================] - 0s 328us/sample - loss: 0.3762 - mae: 0.5165\n",
      "Epoch 31/50\n",
      "297/297 [==============================] - 0s 310us/sample - loss: 0.3778 - mae: 0.5215\n",
      "Epoch 32/50\n",
      "297/297 [==============================] - 0s 308us/sample - loss: 0.3800 - mae: 0.4971\n",
      "Epoch 33/50\n",
      "297/297 [==============================] - 0s 310us/sample - loss: 0.2870 - mae: 0.4540\n",
      "Epoch 34/50\n",
      "297/297 [==============================] - 0s 276us/sample - loss: 0.2975 - mae: 0.4640\n",
      "Epoch 35/50\n",
      "297/297 [==============================] - 0s 314us/sample - loss: 0.3271 - mae: 0.4897\n",
      "Epoch 36/50\n",
      "297/297 [==============================] - 0s 267us/sample - loss: 0.3037 - mae: 0.4670\n",
      "Epoch 37/50\n",
      "297/297 [==============================] - 0s 312us/sample - loss: 0.2394 - mae: 0.3809\n",
      "Epoch 38/50\n",
      "297/297 [==============================] - 0s 307us/sample - loss: 0.2258 - mae: 0.4068\n",
      "Epoch 39/50\n",
      "297/297 [==============================] - 0s 397us/sample - loss: 0.2193 - mae: 0.3610\n",
      "Epoch 40/50\n",
      "297/297 [==============================] - 0s 184us/sample - loss: 0.2355 - mae: 0.4064\n",
      "Epoch 41/50\n",
      "297/297 [==============================] - 0s 219us/sample - loss: 0.1817 - mae: 0.3503\n",
      "Epoch 42/50\n",
      "297/297 [==============================] - 0s 286us/sample - loss: 0.2030 - mae: 0.3277\n",
      "Epoch 43/50\n",
      "297/297 [==============================] - 0s 316us/sample - loss: 0.1904 - mae: 0.3740\n",
      "Epoch 44/50\n",
      "297/297 [==============================] - 0s 349us/sample - loss: 0.1745 - mae: 0.3309\n",
      "Epoch 45/50\n",
      "297/297 [==============================] - 0s 267us/sample - loss: 0.1498 - mae: 0.3052\n",
      "Epoch 46/50\n",
      "297/297 [==============================] - 0s 272us/sample - loss: 0.1633 - mae: 0.3111\n",
      "Epoch 47/50\n",
      "297/297 [==============================] - 0s 273us/sample - loss: 0.1707 - mae: 0.3580\n",
      "Epoch 48/50\n",
      "297/297 [==============================] - 0s 276us/sample - loss: 0.1097 - mae: 0.2638\n",
      "Epoch 49/50\n",
      "297/297 [==============================] - 0s 297us/sample - loss: 0.1217 - mae: 0.2854\n",
      "Epoch 50/50\n",
      "297/297 [==============================] - 0s 275us/sample - loss: 0.1057 - mae: 0.2519\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "       0    1    2      3      4    5    6      7    8    9    10 11  \\\n",
      "87   53.0  0.0  3.0  128.0  216.0  0.0  2.0  115.0  0.0  0.0  1.0  0   \n",
      "166  52.0  1.0  3.0  138.0  223.0  0.0  0.0  169.0  0.0  0.0  1.0  0   \n",
      "192  43.0  1.0  4.0  132.0  247.0  1.0  2.0  143.0  1.0  0.1  2.0  0   \n",
      "266  52.0  1.0  4.0  128.0  204.0  1.0  0.0  156.0  1.0  1.0  2.0  0   \n",
      "287  58.0  1.0  2.0  125.0  220.0  0.0  0.0  144.0  0.0  0.4  2.0  0   \n",
      "302  38.0  1.0  3.0  138.0  175.0  0.0  0.0  173.0  0.0  0.0  1.0  0   \n",
      "\n",
      "           12 13  \n",
      "87   0.841915  0  \n",
      "166         3  0  \n",
      "192         7  1  \n",
      "266  0.937986  2  \n",
      "287         7  0  \n",
      "302         3  0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2      3      4    5    6      7    8    9    10 11  \\\n",
       "0    63.0  1.0  1.0  145.0  233.0  1.0  2.0  150.0  0.0  2.3  3.0  0   \n",
       "1    67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.5  2.0  3   \n",
       "2    67.0  1.0  4.0  120.0  229.0  0.0  2.0  129.0  1.0  2.6  2.0  2   \n",
       "3    37.0  1.0  3.0  130.0  250.0  0.0  0.0  187.0  0.0  3.5  3.0  0   \n",
       "4    41.0  0.0  2.0  130.0  204.0  0.0  2.0  172.0  0.0  1.4  1.0  0   \n",
       "..    ...  ...  ...    ...    ...  ...  ...    ...  ...  ...  ... ..   \n",
       "166  52.0  1.0  3.0  138.0  223.0  0.0  0.0  169.0  0.0  0.0  1.0  0   \n",
       "192  43.0  1.0  4.0  132.0  247.0  1.0  2.0  143.0  1.0  0.1  2.0  0   \n",
       "266  52.0  1.0  4.0  128.0  204.0  1.0  0.0  156.0  1.0  1.0  2.0  0   \n",
       "287  58.0  1.0  2.0  125.0  220.0  0.0  0.0  144.0  0.0  0.4  2.0  0   \n",
       "302  38.0  1.0  3.0  138.0  175.0  0.0  0.0  173.0  0.0  0.0  1.0  0   \n",
       "\n",
       "           12 13  \n",
       "0           6  0  \n",
       "1           3  2  \n",
       "2           7  1  \n",
       "3           3  0  \n",
       "4           3  0  \n",
       "..        ... ..  \n",
       "166         3  0  \n",
       "192         7  1  \n",
       "266  0.937986  2  \n",
       "287         7  0  \n",
       "302         3  0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "#going through all the columns\n",
    "for x in nan_data_columns.loc[1,]:\n",
    "    \n",
    "    #if x = 1 that column has Nan values\n",
    "    if x == 1:\n",
    "        \n",
    "        #data is all but the i column and making labels from the i column\n",
    "        data = df.loc[:, df.columns != i]\n",
    "        labels = 1.0*(df.loc[:, i] > 0)\n",
    "        #print(data.head())\n",
    "        #print(data.shape)\n",
    "        #print(labels.shape)\n",
    "        \n",
    "        #creating the network structure\n",
    "        network = Sequential()\n",
    "        network.add(Dense(13, activation='relu', input_shape=(13,))),\n",
    "        network.add(Dense(52, activation='relu')),\n",
    "        network.add(Dense(1))\n",
    "        network.summary()\n",
    "        \n",
    "        #compiling the network\n",
    "        network.compile(optimizer='rmsprop',loss='mse',\n",
    "              metrics=['mae'])\n",
    "        \n",
    "        #fitting with the non Nan values\n",
    "        network.fit(data, labels, batch_size=10, epochs=50, verbose=1)\n",
    "        \n",
    "        #predicting the Nan values\n",
    "        predict_data = copy.copy(nan_data)\n",
    "        predict_data.drop(predict_data.loc[predict_data[i]!='nan'].index, inplace=True)\n",
    "        predict_data_labels = predict_data.loc[:, i]\n",
    "        \n",
    "        #print(predict_data.loc[:, df.columns != i])\n",
    "        #print(predict_data)\n",
    "        predictions = network.predict(predict_data.loc[:, df.columns != i])\n",
    "        \n",
    "        y = 0\n",
    "        #going through each row and setting the predicted value\n",
    "        for row in predict_data.index:\n",
    "            nan_data.loc[row,i] = predictions[y]\n",
    "            if predictions[y] < 0:\n",
    "                nan_data.loc[row,i] = 0\n",
    "            y = y + 1\n",
    "    i = i + 1\n",
    "print(nan_data)\n",
    "\n",
    "#adding the Nan data with the predicted values to the whole set\n",
    "df.append(nan_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suffeling the data to merge data with generated values to the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffeling the data and creating dataframe + labels\n",
    "df = df.sample(frac=1)\n",
    "data = df.loc[:, 0:12]\n",
    "labels = 1.0*(df.loc[:, 13] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creting the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 13) (198,)\n",
      "       0    1    2      3      4    5    6      7    8    9    10   11   12\n",
      "57   41.0  1.0  4.0  110.0  172.0  0.0  2.0  158.0  0.0  0.0  1.0  0.0  7.0\n",
      "265  42.0  1.0  4.0  136.0  315.0  0.0  0.0  125.0  1.0  1.8  2.0  0.0  6.0\n",
      "9    53.0  1.0  4.0  140.0  203.0  1.0  2.0  155.0  1.0  3.1  3.0  0.0  7.0\n",
      "252  64.0  1.0  4.0  128.0  263.0  0.0  0.0  105.0  1.0  0.2  2.0  1.0  7.0\n",
      "133  51.0  1.0  4.0  140.0  261.0  0.0  2.0  186.0  1.0  0.0  1.0  0.0  3.0\n",
      "(99, 13) (99,)\n",
      "       0    1    2      3      4    5    6      7    8    9    10   11   12\n",
      "270  61.0  1.0  4.0  140.0  207.0  0.0  2.0  138.0  1.0  1.9  1.0  1.0  7.0\n",
      "251  58.0  1.0  4.0  146.0  218.0  0.0  0.0  105.0  0.0  2.0  2.0  1.0  7.0\n",
      "198  50.0  0.0  2.0  120.0  244.0  0.0  0.0  162.0  0.0  1.1  1.0  0.0  3.0\n",
      "177  56.0  1.0  4.0  132.0  184.0  0.0  2.0  105.0  1.0  2.1  2.0  1.0  6.0\n",
      "23   58.0  1.0  3.0  132.0  224.0  0.0  2.0  173.0  0.0  3.2  1.0  2.0  7.0\n"
     ]
    }
   ],
   "source": [
    "sets = np.split(data,3)\n",
    "setlabels = np.split(labels,3)\n",
    "\n",
    "training_data = sets[0].append(sets[1])\n",
    "training_labels = setlabels[0].append(setlabels[1])\n",
    "print(training_data.shape, training_labels.shape)\n",
    "print(training_data.head())\n",
    "\n",
    "test_data = sets[2]\n",
    "test_labels = setlabels[2]\n",
    "print(test_data.shape, test_labels.shape)\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 52)                728       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 53        \n",
      "=================================================================\n",
      "Total params: 963\n",
      "Trainable params: 963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network = Sequential()\n",
    "network.add(Dense(13, activation='relu', input_shape=(13,))),\n",
    "network.add(Dense(52, activation='relu')),\n",
    "network.add(Dense(1, activation='sigmoid'))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 198 samples\n",
      "Epoch 1/150\n",
      "198/198 [==============================] - 1s 5ms/sample - loss: 1.7613 - accuracy: 0.5152\n",
      "Epoch 2/150\n",
      "198/198 [==============================] - 0s 332us/sample - loss: 1.2717 - accuracy: 0.5455\n",
      "Epoch 3/150\n",
      "198/198 [==============================] - 0s 360us/sample - loss: 1.2482 - accuracy: 0.4949\n",
      "Epoch 4/150\n",
      "198/198 [==============================] - 0s 340us/sample - loss: 1.0575 - accuracy: 0.5758\n",
      "Epoch 5/150\n",
      "198/198 [==============================] - 0s 381us/sample - loss: 0.9434 - accuracy: 0.6061\n",
      "Epoch 6/150\n",
      "198/198 [==============================] - 0s 376us/sample - loss: 0.9021 - accuracy: 0.6515\n",
      "Epoch 7/150\n",
      "198/198 [==============================] - 0s 356us/sample - loss: 0.9668 - accuracy: 0.5606\n",
      "Epoch 8/150\n",
      "198/198 [==============================] - 0s 396us/sample - loss: 1.0853 - accuracy: 0.5505\n",
      "Epoch 9/150\n",
      "198/198 [==============================] - 0s 331us/sample - loss: 0.9279 - accuracy: 0.5758\n",
      "Epoch 10/150\n",
      "198/198 [==============================] - 0s 345us/sample - loss: 0.9825 - accuracy: 0.5657\n",
      "Epoch 11/150\n",
      "198/198 [==============================] - 0s 350us/sample - loss: 0.9115 - accuracy: 0.6010\n",
      "Epoch 12/150\n",
      "198/198 [==============================] - 0s 387us/sample - loss: 0.9633 - accuracy: 0.5505\n",
      "Epoch 13/150\n",
      "198/198 [==============================] - 0s 528us/sample - loss: 0.7346 - accuracy: 0.6111\n",
      "Epoch 14/150\n",
      "198/198 [==============================] - 0s 359us/sample - loss: 0.9148 - accuracy: 0.6212\n",
      "Epoch 15/150\n",
      "198/198 [==============================] - 0s 304us/sample - loss: 0.8117 - accuracy: 0.6010\n",
      "Epoch 16/150\n",
      "198/198 [==============================] - 0s 357us/sample - loss: 0.8100 - accuracy: 0.6414\n",
      "Epoch 17/150\n",
      "198/198 [==============================] - 0s 415us/sample - loss: 0.8440 - accuracy: 0.6061\n",
      "Epoch 18/150\n",
      "198/198 [==============================] - 0s 388us/sample - loss: 0.8064 - accuracy: 0.6010\n",
      "Epoch 19/150\n",
      "198/198 [==============================] - 0s 368us/sample - loss: 0.7621 - accuracy: 0.6667\n",
      "Epoch 20/150\n",
      "198/198 [==============================] - 0s 374us/sample - loss: 0.7669 - accuracy: 0.6313\n",
      "Epoch 21/150\n",
      "198/198 [==============================] - 0s 374us/sample - loss: 0.9404 - accuracy: 0.5505\n",
      "Epoch 22/150\n",
      "198/198 [==============================] - 0s 361us/sample - loss: 0.8558 - accuracy: 0.5707\n",
      "Epoch 23/150\n",
      "198/198 [==============================] - 0s 379us/sample - loss: 0.9126 - accuracy: 0.5505\n",
      "Epoch 24/150\n",
      "198/198 [==============================] - 0s 363us/sample - loss: 0.7227 - accuracy: 0.6010\n",
      "Epoch 25/150\n",
      "198/198 [==============================] - 0s 438us/sample - loss: 0.8605 - accuracy: 0.5859\n",
      "Epoch 26/150\n",
      "198/198 [==============================] - 0s 402us/sample - loss: 0.8701 - accuracy: 0.5606\n",
      "Epoch 27/150\n",
      "198/198 [==============================] - 0s 380us/sample - loss: 0.8345 - accuracy: 0.5758\n",
      "Epoch 28/150\n",
      "198/198 [==============================] - 0s 358us/sample - loss: 0.7524 - accuracy: 0.6414\n",
      "Epoch 29/150\n",
      "198/198 [==============================] - 0s 363us/sample - loss: 0.8248 - accuracy: 0.5859\n",
      "Epoch 30/150\n",
      "198/198 [==============================] - 0s 304us/sample - loss: 0.8973 - accuracy: 0.5354\n",
      "Epoch 31/150\n",
      "198/198 [==============================] - 0s 281us/sample - loss: 0.8258 - accuracy: 0.5960\n",
      "Epoch 32/150\n",
      "198/198 [==============================] - 0s 408us/sample - loss: 0.6372 - accuracy: 0.6465\n",
      "Epoch 33/150\n",
      "198/198 [==============================] - 0s 378us/sample - loss: 0.8265 - accuracy: 0.6212\n",
      "Epoch 34/150\n",
      "198/198 [==============================] - 0s 351us/sample - loss: 0.6869 - accuracy: 0.6667\n",
      "Epoch 35/150\n",
      "198/198 [==============================] - 0s 415us/sample - loss: 0.7237 - accuracy: 0.6717\n",
      "Epoch 36/150\n",
      "198/198 [==============================] - 0s 395us/sample - loss: 0.6426 - accuracy: 0.6818\n",
      "Epoch 37/150\n",
      "198/198 [==============================] - 0s 415us/sample - loss: 0.6985 - accuracy: 0.6465\n",
      "Epoch 38/150\n",
      "198/198 [==============================] - 0s 298us/sample - loss: 0.7943 - accuracy: 0.6515\n",
      "Epoch 39/150\n",
      "198/198 [==============================] - 0s 373us/sample - loss: 0.6580 - accuracy: 0.6818\n",
      "Epoch 40/150\n",
      "198/198 [==============================] - 0s 359us/sample - loss: 0.8507 - accuracy: 0.5960\n",
      "Epoch 41/150\n",
      "198/198 [==============================] - 0s 275us/sample - loss: 0.7880 - accuracy: 0.5909\n",
      "Epoch 42/150\n",
      "198/198 [==============================] - 0s 303us/sample - loss: 0.6495 - accuracy: 0.6818\n",
      "Epoch 43/150\n",
      "198/198 [==============================] - 0s 406us/sample - loss: 0.6681 - accuracy: 0.6717\n",
      "Epoch 44/150\n",
      "198/198 [==============================] - 0s 382us/sample - loss: 0.6930 - accuracy: 0.6212\n",
      "Epoch 45/150\n",
      "198/198 [==============================] - 0s 388us/sample - loss: 0.6927 - accuracy: 0.6515\n",
      "Epoch 46/150\n",
      "198/198 [==============================] - 0s 384us/sample - loss: 0.7160 - accuracy: 0.6768\n",
      "Epoch 47/150\n",
      "198/198 [==============================] - 0s 345us/sample - loss: 0.6372 - accuracy: 0.6566\n",
      "Epoch 48/150\n",
      "198/198 [==============================] - 0s 414us/sample - loss: 0.6749 - accuracy: 0.6313\n",
      "Epoch 49/150\n",
      "198/198 [==============================] - 0s 260us/sample - loss: 0.6844 - accuracy: 0.6616\n",
      "Epoch 50/150\n",
      "198/198 [==============================] - 0s 377us/sample - loss: 0.6711 - accuracy: 0.6515\n",
      "Epoch 51/150\n",
      "198/198 [==============================] - 0s 348us/sample - loss: 0.5927 - accuracy: 0.6919\n",
      "Epoch 52/150\n",
      "198/198 [==============================] - 0s 268us/sample - loss: 0.6110 - accuracy: 0.7273\n",
      "Epoch 53/150\n",
      "198/198 [==============================] - 0s 367us/sample - loss: 0.6488 - accuracy: 0.6717\n",
      "Epoch 54/150\n",
      "198/198 [==============================] - 0s 473us/sample - loss: 0.6074 - accuracy: 0.6869\n",
      "Epoch 55/150\n",
      "198/198 [==============================] - 0s 443us/sample - loss: 0.5697 - accuracy: 0.6970\n",
      "Epoch 56/150\n",
      "198/198 [==============================] - 0s 395us/sample - loss: 0.6890 - accuracy: 0.6667\n",
      "Epoch 57/150\n",
      "198/198 [==============================] - 0s 341us/sample - loss: 0.6095 - accuracy: 0.6768\n",
      "Epoch 58/150\n",
      "198/198 [==============================] - 0s 313us/sample - loss: 0.6518 - accuracy: 0.6465\n",
      "Epoch 59/150\n",
      "198/198 [==============================] - 0s 308us/sample - loss: 0.6499 - accuracy: 0.6566\n",
      "Epoch 60/150\n",
      "198/198 [==============================] - 0s 422us/sample - loss: 0.5791 - accuracy: 0.7121\n",
      "Epoch 61/150\n",
      "198/198 [==============================] - 0s 283us/sample - loss: 0.6302 - accuracy: 0.7121\n",
      "Epoch 62/150\n",
      "198/198 [==============================] - 0s 252us/sample - loss: 0.6078 - accuracy: 0.6919\n",
      "Epoch 63/150\n",
      "198/198 [==============================] - 0s 372us/sample - loss: 0.6370 - accuracy: 0.6768\n",
      "Epoch 64/150\n",
      "198/198 [==============================] - 0s 258us/sample - loss: 0.5748 - accuracy: 0.7020\n",
      "Epoch 65/150\n",
      "198/198 [==============================] - 0s 445us/sample - loss: 0.5692 - accuracy: 0.6869\n",
      "Epoch 66/150\n",
      "198/198 [==============================] - 0s 382us/sample - loss: 0.7197 - accuracy: 0.6667\n",
      "Epoch 67/150\n",
      "198/198 [==============================] - 0s 407us/sample - loss: 0.5935 - accuracy: 0.6869\n",
      "Epoch 68/150\n",
      "198/198 [==============================] - 0s 372us/sample - loss: 0.5897 - accuracy: 0.6667\n",
      "Epoch 69/150\n",
      "198/198 [==============================] - 0s 383us/sample - loss: 0.5654 - accuracy: 0.7071\n",
      "Epoch 70/150\n",
      "198/198 [==============================] - 0s 380us/sample - loss: 0.6148 - accuracy: 0.6768\n",
      "Epoch 71/150\n",
      "198/198 [==============================] - 0s 249us/sample - loss: 0.5454 - accuracy: 0.7525\n",
      "Epoch 72/150\n",
      "198/198 [==============================] - 0s 259us/sample - loss: 0.5979 - accuracy: 0.7071\n",
      "Epoch 73/150\n",
      "198/198 [==============================] - 0s 406us/sample - loss: 0.5563 - accuracy: 0.7475\n",
      "Epoch 74/150\n",
      "198/198 [==============================] - 0s 405us/sample - loss: 0.5441 - accuracy: 0.7374\n",
      "Epoch 75/150\n",
      "198/198 [==============================] - 0s 365us/sample - loss: 0.5421 - accuracy: 0.7071\n",
      "Epoch 76/150\n",
      "198/198 [==============================] - 0s 274us/sample - loss: 0.6532 - accuracy: 0.7071\n",
      "Epoch 77/150\n",
      "198/198 [==============================] - 0s 380us/sample - loss: 0.5922 - accuracy: 0.6970\n",
      "Epoch 78/150\n",
      "198/198 [==============================] - 0s 440us/sample - loss: 0.5153 - accuracy: 0.7626\n",
      "Epoch 79/150\n",
      "198/198 [==============================] - 0s 351us/sample - loss: 0.5465 - accuracy: 0.7020\n",
      "Epoch 80/150\n",
      "198/198 [==============================] - 0s 340us/sample - loss: 0.5774 - accuracy: 0.7121\n",
      "Epoch 81/150\n",
      "198/198 [==============================] - 0s 364us/sample - loss: 0.5603 - accuracy: 0.7121\n",
      "Epoch 82/150\n",
      "198/198 [==============================] - 0s 361us/sample - loss: 0.5569 - accuracy: 0.7172\n",
      "Epoch 83/150\n",
      "198/198 [==============================] - 0s 407us/sample - loss: 0.5273 - accuracy: 0.7273\n",
      "Epoch 84/150\n",
      "198/198 [==============================] - 0s 316us/sample - loss: 0.6787 - accuracy: 0.6818\n",
      "Epoch 85/150\n",
      "198/198 [==============================] - 0s 282us/sample - loss: 0.4783 - accuracy: 0.7980\n",
      "Epoch 86/150\n",
      "198/198 [==============================] - 0s 316us/sample - loss: 0.5070 - accuracy: 0.7677\n",
      "Epoch 87/150\n",
      "198/198 [==============================] - 0s 399us/sample - loss: 0.5679 - accuracy: 0.7020\n",
      "Epoch 88/150\n",
      "198/198 [==============================] - 0s 364us/sample - loss: 0.5117 - accuracy: 0.7273\n",
      "Epoch 89/150\n",
      "198/198 [==============================] - 0s 361us/sample - loss: 0.5951 - accuracy: 0.6869\n",
      "Epoch 90/150\n",
      "198/198 [==============================] - 0s 355us/sample - loss: 0.4712 - accuracy: 0.7626\n",
      "Epoch 91/150\n",
      "198/198 [==============================] - 0s 335us/sample - loss: 0.5210 - accuracy: 0.7576\n",
      "Epoch 92/150\n",
      "198/198 [==============================] - 0s 345us/sample - loss: 0.5897 - accuracy: 0.7071\n",
      "Epoch 93/150\n",
      "198/198 [==============================] - 0s 338us/sample - loss: 0.5288 - accuracy: 0.7525\n",
      "Epoch 94/150\n",
      "198/198 [==============================] - 0s 383us/sample - loss: 0.4766 - accuracy: 0.7626\n",
      "Epoch 95/150\n",
      "198/198 [==============================] - 0s 433us/sample - loss: 0.5882 - accuracy: 0.7020\n",
      "Epoch 96/150\n",
      "198/198 [==============================] - 0s 404us/sample - loss: 0.5077 - accuracy: 0.7475\n",
      "Epoch 97/150\n",
      "198/198 [==============================] - 0s 327us/sample - loss: 0.4961 - accuracy: 0.7929\n",
      "Epoch 98/150\n",
      "198/198 [==============================] - 0s 331us/sample - loss: 0.4724 - accuracy: 0.7677\n",
      "Epoch 99/150\n",
      "198/198 [==============================] - 0s 397us/sample - loss: 0.5571 - accuracy: 0.7121\n",
      "Epoch 100/150\n",
      "198/198 [==============================] - 0s 319us/sample - loss: 0.4821 - accuracy: 0.7475\n",
      "Epoch 101/150\n",
      "198/198 [==============================] - 0s 398us/sample - loss: 0.4698 - accuracy: 0.7374\n",
      "Epoch 102/150\n",
      "198/198 [==============================] - 0s 246us/sample - loss: 0.4919 - accuracy: 0.7374\n",
      "Epoch 103/150\n",
      "198/198 [==============================] - 0s 408us/sample - loss: 0.4886 - accuracy: 0.7778\n",
      "Epoch 104/150\n",
      "198/198 [==============================] - 0s 534us/sample - loss: 0.5153 - accuracy: 0.7677\n",
      "Epoch 105/150\n",
      "198/198 [==============================] - 0s 314us/sample - loss: 0.4926 - accuracy: 0.7374\n",
      "Epoch 106/150\n",
      "198/198 [==============================] - 0s 353us/sample - loss: 0.5279 - accuracy: 0.7576\n",
      "Epoch 107/150\n",
      "198/198 [==============================] - 0s 313us/sample - loss: 0.4815 - accuracy: 0.7576\n",
      "Epoch 108/150\n",
      "198/198 [==============================] - 0s 328us/sample - loss: 0.5145 - accuracy: 0.7677\n",
      "Epoch 109/150\n",
      "198/198 [==============================] - 0s 415us/sample - loss: 0.5012 - accuracy: 0.7475\n",
      "Epoch 110/150\n",
      "198/198 [==============================] - 0s 285us/sample - loss: 0.5326 - accuracy: 0.7475\n",
      "Epoch 111/150\n",
      "198/198 [==============================] - 0s 373us/sample - loss: 0.5064 - accuracy: 0.7626\n",
      "Epoch 112/150\n",
      "198/198 [==============================] - 0s 383us/sample - loss: 0.4336 - accuracy: 0.7929\n",
      "Epoch 113/150\n",
      "198/198 [==============================] - 0s 339us/sample - loss: 0.4962 - accuracy: 0.7525\n",
      "Epoch 114/150\n",
      "198/198 [==============================] - 0s 336us/sample - loss: 0.5134 - accuracy: 0.7525\n",
      "Epoch 115/150\n",
      "198/198 [==============================] - 0s 351us/sample - loss: 0.4804 - accuracy: 0.7828\n",
      "Epoch 116/150\n",
      "198/198 [==============================] - 0s 390us/sample - loss: 0.4997 - accuracy: 0.7727\n",
      "Epoch 117/150\n",
      "198/198 [==============================] - 0s 456us/sample - loss: 0.4982 - accuracy: 0.7828\n",
      "Epoch 118/150\n",
      "198/198 [==============================] - 0s 346us/sample - loss: 0.4930 - accuracy: 0.8030\n",
      "Epoch 119/150\n",
      "198/198 [==============================] - 0s 267us/sample - loss: 0.4727 - accuracy: 0.7677\n",
      "Epoch 120/150\n",
      "198/198 [==============================] - 0s 254us/sample - loss: 0.5247 - accuracy: 0.7576\n",
      "Epoch 121/150\n",
      "198/198 [==============================] - 0s 367us/sample - loss: 0.5248 - accuracy: 0.7374\n",
      "Epoch 122/150\n",
      "198/198 [==============================] - 0s 262us/sample - loss: 0.4590 - accuracy: 0.7626\n",
      "Epoch 123/150\n",
      "198/198 [==============================] - 0s 304us/sample - loss: 0.4881 - accuracy: 0.7576\n",
      "Epoch 124/150\n",
      "198/198 [==============================] - 0s 322us/sample - loss: 0.4569 - accuracy: 0.7626\n",
      "Epoch 125/150\n",
      "198/198 [==============================] - 0s 362us/sample - loss: 0.5070 - accuracy: 0.7778\n",
      "Epoch 126/150\n",
      "198/198 [==============================] - 0s 386us/sample - loss: 0.4887 - accuracy: 0.7879\n",
      "Epoch 127/150\n",
      "198/198 [==============================] - 0s 390us/sample - loss: 0.5047 - accuracy: 0.7828\n",
      "Epoch 128/150\n",
      "198/198 [==============================] - 0s 390us/sample - loss: 0.4692 - accuracy: 0.7626\n",
      "Epoch 129/150\n",
      "198/198 [==============================] - 0s 357us/sample - loss: 0.5382 - accuracy: 0.7121\n",
      "Epoch 130/150\n",
      "198/198 [==============================] - 0s 360us/sample - loss: 0.4354 - accuracy: 0.7929\n",
      "Epoch 131/150\n",
      "198/198 [==============================] - 0s 388us/sample - loss: 0.4562 - accuracy: 0.7929\n",
      "Epoch 132/150\n",
      "198/198 [==============================] - 0s 352us/sample - loss: 0.4885 - accuracy: 0.7677\n",
      "Epoch 133/150\n",
      "198/198 [==============================] - 0s 339us/sample - loss: 0.4466 - accuracy: 0.7879\n",
      "Epoch 134/150\n",
      "198/198 [==============================] - 0s 375us/sample - loss: 0.5037 - accuracy: 0.7525\n",
      "Epoch 135/150\n",
      "198/198 [==============================] - 0s 376us/sample - loss: 0.4365 - accuracy: 0.8081\n",
      "Epoch 136/150\n",
      "198/198 [==============================] - 0s 358us/sample - loss: 0.4361 - accuracy: 0.8081\n",
      "Epoch 137/150\n",
      "198/198 [==============================] - 0s 347us/sample - loss: 0.4605 - accuracy: 0.7778\n",
      "Epoch 138/150\n",
      "198/198 [==============================] - 0s 246us/sample - loss: 0.4323 - accuracy: 0.7727\n",
      "Epoch 139/150\n",
      "198/198 [==============================] - 0s 340us/sample - loss: 0.5308 - accuracy: 0.7525\n",
      "Epoch 140/150\n",
      "198/198 [==============================] - 0s 368us/sample - loss: 0.4546 - accuracy: 0.7980\n",
      "Epoch 141/150\n",
      "198/198 [==============================] - 0s 376us/sample - loss: 0.4812 - accuracy: 0.7727\n",
      "Epoch 142/150\n",
      "198/198 [==============================] - 0s 284us/sample - loss: 0.3960 - accuracy: 0.7980\n",
      "Epoch 143/150\n",
      "198/198 [==============================] - 0s 466us/sample - loss: 0.5073 - accuracy: 0.7677\n",
      "Epoch 144/150\n",
      "198/198 [==============================] - 0s 291us/sample - loss: 0.4254 - accuracy: 0.7828\n",
      "Epoch 145/150\n",
      "198/198 [==============================] - 0s 269us/sample - loss: 0.4881 - accuracy: 0.8030\n",
      "Epoch 146/150\n",
      "198/198 [==============================] - 0s 386us/sample - loss: 0.4052 - accuracy: 0.8232\n",
      "Epoch 147/150\n",
      "198/198 [==============================] - 0s 297us/sample - loss: 0.4421 - accuracy: 0.7929\n",
      "Epoch 148/150\n",
      "198/198 [==============================] - 0s 296us/sample - loss: 0.3968 - accuracy: 0.8182\n",
      "Epoch 149/150\n",
      "198/198 [==============================] - 0s 340us/sample - loss: 0.5132 - accuracy: 0.7677\n",
      "Epoch 150/150\n",
      "198/198 [==============================] - 0s 292us/sample - loss: 0.3930 - accuracy: 0.7980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x156a6b86648>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.compile(optimizer='rmsprop',loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "network.fit(training_data, training_labels, batch_size=10, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "99/99 [==============================] - 0s 2ms/sample - loss: 0.3060 - accuracy: 0.8687\n",
      "Test accuracy: 0.86868685\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
